#summary リファレンスハードウェアシミュレータプログラム

= リファレンスハードウェアシミュレータプログラム =

== 概要 ==

　知能化プロジェクトの一環として，開発されたアーム部，台車部，カメラ，URGセンサなどから構成されるリファレンスハードウェアのナビゲーションのシミュレータが開発されてきている．ここでは，リファレンスハードウェア2号機を対象とした統合検証システムとして，OpenHRP3と連携して自己位置推定，障害物回避，ナビゲーションなどを行うプログラムを紹介する．

　本シミュレータプログラムの公開にあたり，産総研知能システム研究部門サービスロボティクス研究グループ田中秀幸さま，富士ソフト株式会社ロボット事業グループ商品開発ユニット二宮恒樹さま，産業技術総合研究所知能システム研究部門サービスロボティクス研究グループ松本吉央さまには，大変お世話になりました．どうもありがとうございます．

== 準備 ==

岡田先生が全てコンパイルできる環境を整えてくださったので，ソース一式の入手，コンパイル等はROSのシステムを利用して行う．

従って以下のサンプルは全てUbuntu10.04上での動作を前提とする．

rtm-ros-robotics/rtmros_common/RS003がない場合には，rtmros_common以下でsvn upしてからrosmake RS003を行う．

また，このサンプルを試すにはジョイスティックをPCに差して置く必要がある．ジョイスティックの動作確認は

{{{
$ jstest /dev/input/js0
}}}

で行うことができる．

また，ナビゲーションデモを行うためには，routemapを絶対パスで指定する必要がある．
{{{
$ roscd RS003/src/PathPlanning
}}}
をした場所にあるPathPlanningParam.confの中の
{{{
conf.default.map_file: /home/lrtmros/prog/rtm-ros-robotics/rtmros_common/RS003/src/PathPlanning/routemap
}}}
を各自の環境に合わせて変更する必要がある．routemapはRS003/src/PathPlanningにあるので，それを絶対パスで指定するように修正する．

== サンプルの試し方 ==

=== ジョイスティック操縦デモ===

ジョイスティックをPCに差した状態で，

{{{
$ roslaunch RS003 rh.launch
}}}

を行うと次々にコンポーネントが立ち上がるが，GRXUIが起動したらすかさずシミュレーションスタートのボタンを押すとうまくいき，下図のような状態になる．

[http://rtm-ros-robotics.googlecode.com/svn/wiki/ScreenshotRHSample.png]

上記のコマンドで，うまく全てのコンポーネントが立ち上がると，ジョイスティックを利用してOpenHRP3内のロボットを操作しながら天井画像による自己位置推定を行う様子を確認することができる．

=== ナビゲーションデモ===

上記のrh.launchを立ち上げた状態でeclipseをもう一つ立ち上げ，RTSystemEditorを起動する．そして，PositionInput0をSystem Diagram上にドラッグアンドドロップし，01_x, 02_y, 03_thをそれぞれ編集する．ナビゲーションでいける場所は予め定められており，RS003/src/LocalizeCenter/LocalPosition.confに記述された場所のいずれかの値をここでは入力して，Applyを押すこと．

そして，そこで，PositionInput0をActivateすると下図のように経路計画が行われ，自動的に目標値に向かって進むデモを見ることができる．目的地に到達した後は，PositionInput0をDeactivateし，再び別の場所の位置を指定してActivateしなおせば新たな地点への移動を行う様子をみることができる．

[http://rtm-ros-robotics.googlecode.com/svn/wiki/ScreenshotRHNavigationSample.png]