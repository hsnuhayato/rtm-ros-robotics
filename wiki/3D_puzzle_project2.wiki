#summary One-sentence summary of this page.


= 11/30 =

 * 目標：environment with multiple pieces, grasp one piece, put in container
   （先週のつづき）

 * AR markerでピースの姿勢認識
  * marker->pieceの座標変換を入れて，piece姿勢の認識を可能とする
  * 認識結果をシミュレータ内に反映させる
  * cubeassembly.pyとの整合性をとる
  * 適宜、実機で正しく認識できるかどうか確認する

 * OpenRAVEとHIRONX実機の接続
  * cubeassembly.pyのMoveHandPositionなどの位置で，実機にコマンドを送るコードを入れる
  * 簡単な軌道を生成し、出力された軌道を実機に送ってみる
  * 手が台車部に当たらないようにモデルを修正し、実機で実行可能な軌道を生成する
  * できるだけ容易に把持可能なシーンを作成する
  * 環境中に箱を入れる
  * 机上の複数のpieceを探す動作を実装する

 * 実機で掴みやすい配置のpieceを１つずつ把持し，箱に入れる


 * pieceの認識結果のOpenRAVE環境に反映する(mytest3.py)
  * ARマーカ=>pieceのtransformは考慮していない




= 今後の目標 =

 * Nicely-ordered pieces (easy-solution exists). Put in goal (cube) configuration
 * Randomly-ordered pieces (hard). Put in goal (cube) configuration
 * Put complex obstacles and detect them with the Kinect.
 * Make it very fast


= その他 =

* 画像によるピース認識

 * 平面的なピース認識(yellow,red,brown,aqua,yellowgreen)
{{{
 roscd piece_recog
 rosmake
 rosrun piece_recog piece_recog_node image:=/hiro/lhand/usb_cam/image_raw
 rosservice call /set_target_piece yellow  # サービスで認識対象を設定
 rostopic echo /tf  # tfが出力される
 rosrun rviz rviz  # /camera->/piece を表示してみる
}}}


* Kinectによる障害物（対象物以外の環境）認識

 * camera_infoは設定ファイルから読み込めるように作られていないので、openni_nodelet.cppを直接編集して書きこむ (diamondback)

* ステレオ視

* HiroNX制御RTC(Act共通インタフェース)
 * OpenRTM-javaでRTC実装された制御モジュール
 * 今後、こちらに置き換えていく
 * フラットな関節角度ベクトルを引数に与える
{{{
 q = rr.get_joint_angles()
 q[0] += 0.2
 rr.send_goal(q, 3.0, True)
}}}
 